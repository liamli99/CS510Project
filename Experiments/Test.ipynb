{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def test(input1, input2):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    lst = [input1, input2]\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(lst)\n",
    "    similarity = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
    "\n",
    "    return similarity\n",
    "\n",
    "print(test(\"tomato apple banana onion fish\", \"banana fish apple onion tomato\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def not_include(lst, str):\n",
    "    return all(ele not in str for ele in lst)\n",
    "\n",
    "print (not_include(['soda', 'chicke'], \"tomato apple banana onion fish\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is are take took taken cat cat quiz quiz divide divided dry dried\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def lemmatization(ingredients):\n",
    "    # nltk.download('wordnet')\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words_list = word_tokenize(ingredients)\n",
    "    \n",
    "    lemmatized_words_list = [lemmatizer.lemmatize(word) for word in words_list]\n",
    "    lemmatized_words_str = ' '.join(lemmatized_words_list)\n",
    "\n",
    "    return lemmatized_words_str\n",
    "\n",
    "print(lemmatization(\"is are take took taken cat cats quiz quizzes divide divided dry dried\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be be take take take cat cat quiz quiz divide divide dry dry\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def lemmatization(ingredients):\n",
    "    # spacy.cli.download(\"en_core_web_sm\")\n",
    "    # Load the English NLP model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    # Process the text\n",
    "    doc = nlp(ingredients)\n",
    "\n",
    "    # Lemmatize each token\n",
    "    lemmatized_words_list = [token.lemma_ for token in doc]\n",
    "    lemmatized_words_str = ' '.join(lemmatized_words_list)\n",
    "    \n",
    "    return lemmatized_words_str\n",
    "\n",
    "print(lemmatization(\"is are take took taken cat cats quiz quizzes divide divided dry dried\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Open an image file\n",
    "image = Image.open('archive/images/miso-butter-roast-chicken-acorn-squash-panzanella.jpg')\n",
    "\n",
    "# Display the image\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "\n",
    "data = pickle.load(open(\"../data.pkl\", 'rb'))\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recommend1(title, df):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['Cleaned_Ingredients'])\n",
    "    similarity = cosine_similarity(tfidf_matrix)\n",
    "    \n",
    "    index = df[df['Title'] == title].index[0]\n",
    "    recommended_list = sorted(list(enumerate(0.5 * similarity[index] + 0.5 * df['Rating'])), reverse=True, key=lambda x: x[1])\n",
    "    recommended_recipes = []\n",
    "    \n",
    "    for i in recommended_list[0:5]:\n",
    "        recommended_recipes.append(df.iloc[i[0]].Title)\n",
    "    \n",
    "    return similarity[index].shape\n",
    "\n",
    "def recommend2(inputValue1, inputValue2, df):\n",
    "    filtered_df = df.copy()\n",
    "\n",
    "    def not_include(lst, str):\n",
    "        return all(ele not in str for ele in lst)\n",
    "    \n",
    "    if inputValue1 != \"\":\n",
    "        inputValue1_lst = re.split('[, ]+', inputValue1.lower())\n",
    "        mask = filtered_df.apply(lambda row: not_include(inputValue1_lst, row['Cleaned_Ingredients']), axis=1)\n",
    "        filtered_df = filtered_df[mask]\n",
    "        \n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "    all_texts = filtered_df['Cleaned_Ingredients'].tolist() + [inputValue2]\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(all_texts)\n",
    "\n",
    "    input_vector = tfidf_matrix[-1]\n",
    "    similarity = cosine_similarity(tfidf_matrix[:-1], input_vector)\n",
    "\n",
    "    filtered_df['Similarity'] = similarity\n",
    "    filtered_df['Recommendation_Metric'] = similarity.squeeze() + filtered_df['Rating']\n",
    "\n",
    "    recommended_list = filtered_df.sort_values(by='Recommendation_Metric', ascending=False).head(5)\n",
    "    recommended_recipes = []\n",
    "    recommended_similarity = []\n",
    "\n",
    "    recommended_stats = []\n",
    "    \n",
    "    for recipes in recommended_list['Title']:\n",
    "        recommended_recipes.append(recipes)\n",
    "\n",
    "    for sim in recommended_list['Recommendation_Metric']:\n",
    "        recommended_similarity.append(sim)\n",
    "    \n",
    "    for _, row in recommended_list.iterrows():\n",
    "        recommended_stats.append(type(row['Rating']))\n",
    "        \n",
    "    return recommended_stats\n",
    "\n",
    "print(recommend2(\"olive\", \"onion\", data))\n",
    "# print(recommend1(\"Miso-Butter Roast Chicken With Acorn Squash Panzanella\", data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Crispy Salt and Pepper Potatoes', 'Crispy Salt-and-Vinegar Potatoes', 'Crispy Salt-and-Pepper Chicken Skin', 'Salt-and-Pepper Shrimp', 'Salt and Pepper Shrimp', 'Salt-And-Pepper Steak', 'Salt-Roasted Potatoes', 'Salt-and-Pepper Fish', 'Crispy Salt and Pepper Chicken with Caramelized Fennel and Shallots', 'Salt-and-Pepper Biscuits']\n",
      "['Crispy Salt and Pepper Potatoes', 'Crispy Salt-and-Vinegar Potatoes', 'Crispy Salt-and-Pepper Chicken Skin', 'Salt and Pepper Shrimp', 'Salt-and-Pepper Shrimp', 'Salt-And-Pepper Steak', 'Salt-Roasted Potatoes', 'Salt-and-Pepper Fish', 'Crispy Salt and Pepper Chicken with Caramelized Fennel and Shallots', 'Salt-and-Pepper Biscuits']\n",
      "['Crispy Salt and Pepper Potatoes', 'Crispy Salt-and-Vinegar Potatoes', 'Crispy Salt-and-Pepper Chicken Skin', 'Salt and Pepper Shrimp', 'Salt-and-Pepper Shrimp', 'Salt-And-Pepper Steak', 'Salt-Roasted Potatoes', 'Salt-and-Pepper Fish', 'Crispy Salt and Pepper Chicken with Caramelized Fennel and Shallots', 'Salt-and-Pepper Biscuits']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "data = pickle.load(open(\"../data.pkl\", 'rb'))\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recommend1(title, df):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['Title'])\n",
    "    similarity = cosine_similarity(tfidf_matrix)\n",
    "    \n",
    "    index = df[df['Title'] == title].index[0]\n",
    "    recommended_list = sorted(list(enumerate(0.5 * similarity[index] + 0.5 * df['Rating'])), reverse=True, key=lambda x: x[1])\n",
    "    recommended_recipes = []\n",
    "    \n",
    "    for i in recommended_list[0:10]:\n",
    "        recommended_recipes.append(df.iloc[i[0]].Title)\n",
    "    \n",
    "    return recommended_recipes\n",
    "\n",
    "def recommend1_1(title, df):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['Title'])\n",
    "    similarity = cosine_similarity(tfidf_matrix)\n",
    "    \n",
    "    index = df[df['Title'] == title].index[0]\n",
    "\n",
    "    df['Similarity'] = similarity[index]\n",
    "    recommended_df = df.sort_values(by='Similarity', ascending=False).head(10)\n",
    "    \n",
    "    recommended_recipes_titles = []\n",
    "    \n",
    "    for recipes_title in recommended_df['Title']:\n",
    "        recommended_recipes_titles.append(recipes_title)\n",
    "    \n",
    "    return recommended_recipes_titles\n",
    "\n",
    "def recommend1_2(title, df):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['Title'])\n",
    "    \n",
    "    index = df[df['Title'] == title].index[0]\n",
    "\n",
    "    similarity = cosine_similarity(tfidf_matrix, tfidf_matrix[index])\n",
    "\n",
    "\n",
    "    df['Similarity'] = similarity\n",
    "    recommended_df = df.sort_values(by='Similarity', ascending=False).head(10)\n",
    "    \n",
    "    recommended_recipes_titles = []\n",
    "    \n",
    "    for recipes_title in recommended_df['Title']:\n",
    "        recommended_recipes_titles.append(recipes_title)\n",
    "    \n",
    "    return recommended_recipes_titles\n",
    "\n",
    "\n",
    "print(recommend1('Crispy Salt and Pepper Potatoes', data))\n",
    "print(recommend1_1('Crispy Salt and Pepper Potatoes', data))\n",
    "print(recommend1_2('Crispy Salt and Pepper Potatoes', data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
